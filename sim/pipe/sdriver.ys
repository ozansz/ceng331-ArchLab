#######################################################################
# Test for copying block of size 4;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $4, %rdx		# src and dst have 4 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
    # corrupt all the unused registers to prevent assumptions
    irmovq $0x5710331, %rax
    irmovq $0x5710331, %rcx
    irmovq $0x5710331, %rbp
    irmovq $0x5710331, %r8
    irmovq $0x5710331, %r9
    irmovq $0x5710331, %r10
    irmovq $0x5710331, %r11
    irmovq $0x5710331, %r12
    irmovq $0x5710331, %r13
    irmovq $0x5710331, %r14
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion

	xorq %rax, %rax
test1:
	iaddq $-1, %rdx
	je len1
	iaddq $1, %rdx
test9:
	iaddq $-9, %rdx
	jge len9
test4:
	iaddq $5, %rdx
	jge len4
test2:
	iaddq $3, %rdx
	jg len2
	je len1
	ret
len4:
	mrmovq     (%rdi), %r8
	mrmovq  0x8(%rdi), %r9
	mrmovq 0x10(%rdi), %r10
	mrmovq 0x18(%rdi), %r11
	rmmovq %r8,      (%rsi)
	rmmovq %r9,   0x8(%rsi)
	rmmovq %r10, 0x10(%rsi)
	rmmovq %r11, 0x18(%rsi)
	andq %r8, %r8		
	jle inc41	
	iaddq $1, %rax
inc41:
	andq %r9, %r9		
	jle inc42
	iaddq $1, %rax
inc42:
	andq %r10, %r10		
	jle inc43
	iaddq $1, %rax
inc43:
	andq %r11, %r11
	jle fb4
	iaddq $1, %rax
fb4:
	iaddq $32, %rdi
	iaddq $32, %rsi
	iaddq $-9, %rdx
	jmp test4
len9:
	mrmovq     (%rdi), %r8
	mrmovq  0x8(%rdi), %r9
	mrmovq 0x10(%rdi), %r10
	mrmovq 0x18(%rdi), %r11
	mrmovq 0x20(%rdi), %r12
	mrmovq 0x28(%rdi), %r13
	mrmovq 0x30(%rdi), %r14
	mrmovq 0x38(%rdi), %rbx
	mrmovq 0x40(%rdi), %rcx
	rmmovq %r8,      (%rsi)
	rmmovq %r9,   0x8(%rsi)
	rmmovq %r10, 0x10(%rsi)
	rmmovq %r11, 0x18(%rsi)
	rmmovq %r12, 0x20(%rsi)
	rmmovq %r13, 0x28(%rsi)
	rmmovq %r14, 0x30(%rsi)
	rmmovq %rbx, 0x38(%rsi)
	rmmovq %rcx, 0x40(%rsi)
	andq %r8, %r8		
	jle inc91	
	iaddq $1, %rax
inc91:
	andq %r9, %r9		
	jle inc92
	iaddq $1, %rax
inc92:
	andq %r10, %r10
	jle inc93
	iaddq $1, %rax
inc93:
	andq %r11, %r11	
	jle inc94
	iaddq $1, %rax
inc94:
	andq %r12, %r12	
	jle inc95
	iaddq $1, %rax
inc95:
	andq %r13, %r13	
	jle inc96
	iaddq $1, %rax
inc96:
	andq %r14, %r14	
	jle inc97
	iaddq $1, %rax
inc97:
	andq %rbx, %rbx				
	jle inc98
	iaddq $1, %rax
inc98:
	andq %rcx, %rcx				
	jle fb9
	iaddq $1, %rax
fb9:
	iaddq $72, %rdi
	iaddq $72, %rsi
	jmp test9
len2:
	mrmovq (%rdi), %r8
	mrmovq 0x8(%rdi), %r9
	rmmovq %r8, (%rsi)
	rmmovq %r9, 0x8(%rsi)
	andq %r8, %r8		
	jle inc21	
	iaddq $1, %rax
inc21:
	andq %r9, %r9		
	jle fb2
	iaddq $1, %rax
fb2:
	iaddq $16, %rdi
	iaddq $16, %rsi
	iaddq $-1, %rdx
	je Done
len1:
	mrmovq (%rdi), %r8
	rmmovq %r8, (%rsi)
	andq %r8, %r8		
	jle Done	
	iaddq $1, %rax		
##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad -2
	.quad 3
	.quad -4
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
